{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 14:02:16.230299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-07 14:02:16.230337: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-07 14:02:19.858 | INFO     | __main__:get_eeg:26 - Data is downloaded to ../../data/raw/datasets/eeg.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 14])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from loguru import logger\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from scipy.io import arff\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "def get_eeg(data_dir: Path = \"../../data/raw\") -> Path:\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "    datapath = tf.keras.utils.get_file(\n",
    "        \"eeg\", origin=url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "    datapath = Path(datapath)\n",
    "    logger.info(f\"Data is downloaded to {datapath}.\")\n",
    "    return datapath\n",
    "\n",
    "class BaseDataset:\n",
    "    def __init__(self, datapath: Path):\n",
    "        self.path = datapath\n",
    "        self.data = self.process_data()\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        data = arff.loadarff(self.path)\n",
    "        first_label = int(data[0][0][14])\n",
    "        label = first_label\n",
    "        chunck = []\n",
    "        chuncks = []\n",
    "        for line in data[0]:\n",
    "            if int(line[14]) == label:\n",
    "                observation = []\n",
    "                for index, i in enumerate(line):\n",
    "                    if index != 14:\n",
    "                        observation.append(i)\n",
    "                observation = torch.Tensor(observation)\n",
    "                chunck.append(observation)\n",
    "            else:\n",
    "                chunck_tuple = (label, torch.stack(chunck))\n",
    "                chuncks.append(chunck_tuple)\n",
    "                label = int(line[14])\n",
    "                chunck = []\n",
    "                observation = []\n",
    "                for index, i in enumerate(line):\n",
    "                    if index != 14:\n",
    "                        observation.append(i)\n",
    "                observation = torch.Tensor(observation)\n",
    "                chunck.append(observation)\n",
    "        chunck_tuple = (label, torch.stack(chunck))\n",
    "        chuncks.append(chunck_tuple)\n",
    "        return chuncks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        x = item[1]\n",
    "        y = item[0]\n",
    "        return x,y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        length = len(self.data)\n",
    "        return length\n",
    "\n",
    "\n",
    "dataloader = BaseDataset(datapath = get_eeg())\n",
    "dataloader.__getitem__(23)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000005vscode-remote?line=1'>2</a>\u001b[0m data\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000005vscode-remote?line=3'>4</a>\u001b[0m data_split \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msplit(data, \u001b[39m9\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000005vscode-remote?line=4'>5</a>\u001b[0m data_split[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "data = torch.rand(10,14)\n",
    "data\n",
    "\n",
    "data_split = torch.split(data, 9)\n",
    "data_split[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#om obs in stukken te splitten: torch.split()\n",
    "#niet elke batch hoeft dezelfde lengte te hebben of torch.cat()\n",
    "#elk item uit dezelfde batch mag uit dezelfde obs komen\n",
    "#self.buffer = []\n",
    "#for .. in ..\n",
    "#batch = self.buffer[:32]\n",
    "#self.buffer = self.buffer[32:]\n",
    "\n",
    "\n",
    "#examen iets met een dataloader\n",
    "#we krijgen een dataset + dataloader, maak model, train model, experimenteer met model\n",
    "#relatie met trax - hier is plaatje, maak dit in trax.\n",
    "#als je maar weinig tijdsstappen hebt (5 oid), geen gru of lstm nodig, maar rnn is beter\n",
    "\n",
    "#git config --get remote.origin.url\n",
    "#git remote --set \n",
    "\n",
    "class BaseDatastreamer:\n",
    "    \"\"\"This datastreamer wil never stop\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: BaseDataset,\n",
    "        batchsize: int\n",
    "    ) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.size = len(self.dataset)\n",
    "        self.reset_index()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def reset_index(self) -> None:\n",
    "        self.index_list = np.random.permutation(self.size)\n",
    "        self.index = 0\n",
    "\n",
    "    def batchloop(self) -> Sequence[Tuple]:\n",
    "        batch = []\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.get_chunck()\n",
    "            batch.append((x, y))\n",
    "            self.index += 1\n",
    "        return batch\n",
    "\n",
    "    def stream(self) -> Iterator:\n",
    "        while True:\n",
    "            if self.index > (self.size - self.batchsize):\n",
    "                self.reset_index()\n",
    "            batch = self.batchloop()\n",
    "            if self.preprocessor is not None:\n",
    "                X, Y = self.preprocessor(batch)  # noqa N806\n",
    "            else:\n",
    "                X, Y = zip(*batch)  # noqa N806\n",
    "            yield X, Y\n",
    "\n",
    "class EEGStreamer(BaseDatastreamer):\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        super().__init__(dataset, window_size, batchsize)\n",
    "            \n",
    "    def get_chuck(self):\n",
    "        \n",
    "\n",
    "    \n",
    "    def batchloop(self) -> Sequence[Tuple]:\n",
    "        batch = []\n",
    "        for _ in range(self.batchsize):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-07 14:02:20.877 | INFO     | __main__:get_eeg:26 - Data is downloaded to ../../data/raw/datasets/eeg.\n"
     ]
    }
   ],
   "source": [
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        self.dataset = dataset #set dataset\n",
    "        self.batchsize = batchsize #set batchsize\n",
    "        self.window_size = window_size #set windowsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        window_size = self.window_size\n",
    "        self.count = 0 #init count\n",
    "        for i in self.dataset: #loop through all observations\n",
    "            lenght_observation = i[0].shape[0] #get nr of rows in the observation\n",
    "            if lenght_observation < window_size:\n",
    "                items_obs = 1\n",
    "            else:\n",
    "                items_obs = lenght_observation-window_size+1 #get possible nr of windows from observation\n",
    "            self.count += items_obs #increment count\n",
    "        return self.count #return max nr of items\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator: \n",
    "        self.index_list = range(0,15000)\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        X, Y = self.batchloop()  # noqa N806\n",
    "        return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "    def window(self, x: Tensor, n_time: int) -> Tensor: #function to get windowed items from observation\n",
    "        \"\"\"\n",
    "        Generates and index that can be used to window a timeseries.\n",
    "        E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "        length 3 like this:\n",
    "\n",
    "        [0, 1, 2]\n",
    "        [1, 2, 3]\n",
    "        [2, 3, 4]\n",
    "        [3, 4, 5]\n",
    "\n",
    "        We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "        with the same length.\n",
    "        \"\"\"\n",
    "        n_window = len(x) - n_time + 1\n",
    "        time = torch.arange(0, n_time).reshape(1, -1)\n",
    "        window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "        idx = time + window\n",
    "        return idx\n",
    "\n",
    "    def get_chuck(self):\n",
    "        i = random.randint(0,23)\n",
    "        observation = self.dataset.__getitem__(i)\n",
    "        chunck = torch.split(observation,)\n",
    "\n",
    "    def get_windowed_item(self):\n",
    "        window_size = self.window_size #get window size\n",
    "        itemIndexes = self.dict_iterator[self.index]\n",
    "        x,y = self.dataset.__getitem__(itemIndexes[0]) #get the item and store in x and y\n",
    "        if self.window_size > int(x.shape[0]): #if the window size is larger than the nr of lines in observation\n",
    "            idx = self.window(x, x.shape[0]) #take the whole item\n",
    "        else: # if the window size is smaller than the nr of lines in the observation\n",
    "            idx = self.window(x, window_size) #use window function to get windowed sample\n",
    "        currentObservation = x[idx] #apply idx to currentobservation\n",
    "        currentitem = currentObservation[itemIndexes[1]] #get one windowed item\n",
    "        return currentitem, y #return windowed item and its class\n",
    "\n",
    "    def batchloop(self) -> Tuple[List, List]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        for _ in range(self.batchsize): \n",
    "            x,y = self.get_windowed_item()\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    \"\"\"Iterator with additional padding of X\n",
    "\n",
    "    Args:\n",
    "        BaseDataIterator (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        super().__init__(dataset, window_size, batchsize)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index <= (len(self) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0) #if there are shorter sequences, add padding\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "dataset = BaseDataset(datapath = get_eeg())\n",
    "loader = BaseDataIterator(dataset = dataset, window_size=30, batchsize=32)\n",
    "\n",
    "#moeten we ervoor zorgen dat elk window max 1 keer gebruikt wordt of is het ok dat er een kleine \n",
    "# kans bestaat dat iets dubben gebruikt wordt\n",
    "\n",
    "#omgaan met train en test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaseDataIterator' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(loader)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(loader)\n",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb Cell 2'\u001b[0m in \u001b[0;36mBaseDataIterator.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000001vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseDataIterator: \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000001vscode-remote?line=19'>20</a>\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcount \u001b[39m#get the max nr of iterations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000001vscode-remote?line=20'>21</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdict_iterator \u001b[39m=\u001b[39m {} \u001b[39m#init dict to store indexes \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/Dataloader.ipynb#ch0000001vscode-remote?line=21'>22</a>\u001b[0m     lengthobs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset) \u001b[39m#get nr of observations\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseDataIterator' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "iterator = iter(loader)\n",
    "batch = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        self.dataset = dataset #set dataset\n",
    "        self.batchsize = batchsize #set batchsize\n",
    "        self.window_size = window_size #set windowsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        window_size = self.window_size\n",
    "        self.count = 0 #init count\n",
    "        for i in self.dataset: #loop through all observations\n",
    "            lenght_observation = i[0].shape[0] #get nr of rows in the observation\n",
    "            if lenght_observation < window_size:\n",
    "                items_obs = 1\n",
    "            else:\n",
    "                items_obs = lenght_observation-window_size+1 #get possible nr of windows from observation\n",
    "            self.count += items_obs #increment count\n",
    "        return int(self.count / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator: \n",
    "        window_size = self.window_size\n",
    "        self.count = 0 #init count\n",
    "        item = self.dataset(random.randint(0,len(self.dataset)))\n",
    "\n",
    "        for i in self.dataset: #loop through all observations\n",
    "            lenght_observation = i[0].shape[0] #get nr of rows in the observation\n",
    "            if lenght_observation < window_size:\n",
    "                items_obs = 1\n",
    "            else:\n",
    "                items_obs = lenght_observation-window_size+1 #get possible nr of windows from observation\n",
    "            self.count += items_obs #increment count\n",
    "        \n",
    "        \n",
    "        lengthobs = len(self.dataset) #get nr of observations\n",
    "        for i in range(lengthobs):\n",
    "            x,y = dataset.__getitem__(i)\n",
    "            lenght_item = x.shape[0]-self.window_size+1\n",
    "\n",
    "        length = self.length #get the max nr of iterations\n",
    "        self.dict_iterator = {} #init dict to store indexes \n",
    "        lengthobs = len(self.dataset) #get nr of observations\n",
    "        index_tuples = [] #to store max nr tuples in\n",
    "        for i in range(lengthobs):\n",
    "            x,y = dataset.__getitem__(i) \n",
    "            lenght_item = x.shape[0]-self.window_size+1 \n",
    "            index_tuples.append((i, lenght_item)) \n",
    "        for item in range(self.count):\n",
    "            obs = random.randint(0,23)\n",
    "            self.dict_iterator[item] = (obs, random.randint(0, index_tuples[obs][1]))\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        X, Y = self.batchloop()  # noqa N806\n",
    "        return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "    def window(self, x: Tensor, n_time: int) -> Tensor: #function to get windowed items from observation\n",
    "        \"\"\"\n",
    "        Generates and index that can be used to window a timeseries.\n",
    "        E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "        length 3 like this:\n",
    "\n",
    "        [0, 1, 2]\n",
    "        [1, 2, 3]\n",
    "        [2, 3, 4]\n",
    "        [3, 4, 5]\n",
    "\n",
    "        We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "        with the same length.\n",
    "        \"\"\"\n",
    "        n_window = len(x) - n_time + 1\n",
    "        time = torch.arange(0, n_time).reshape(1, -1)\n",
    "        window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "        idx = time + window\n",
    "        return idx\n",
    "\n",
    "    def get_windowed_item(self):\n",
    "        print(self.index)\n",
    "        window_size = self.window_size #get window size\n",
    "        itemIndexes = self.dict_iterator[self.index]\n",
    "        print(itemIndexes)\n",
    "        x,y = self.dataset.__getitem__(itemIndexes[0]) #get the item and store in x and y\n",
    "        if self.window_size > int(x.shape[0]): #if the window size is larger than the nr of lines in observation\n",
    "            idx = self.window(x, x.shape[0]) #take the whole item\n",
    "        else: # if the window size is smaller than the nr of lines in the observation\n",
    "            idx = self.window(x, window_size) #use window function to get windowed sample\n",
    "        currentObservation = x[idx] #apply idx to currentobservation\n",
    "        currentitem = currentObservation[itemIndexes[1]] #get one windowed item\n",
    "        return currentitem, y #return windowed item and its class\n",
    "\n",
    "    def batchloop(self) -> Tuple[List, List]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        for _ in range(self.batchsize): \n",
    "            x,y = self.get_windowed_item()\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    \"\"\"Iterator with additional padding of X\n",
    "\n",
    "    Args:\n",
    "        BaseDataIterator (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        super().__init__(dataset, window_size, batchsize)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index <= (len(self) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0) #if there are shorter sequences, add padding\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "dataset = BaseDataset(datapath = get_eeg())\n",
    "loader = BaseDataIterator(dataset = dataset, window_size=30, batchsize=32)\n",
    "\n",
    "#moeten we ervoor zorgen dat elk window max 1 keer gebruikt wordt of is het ok dat er een kleine \n",
    "# kans bestaat dat iets dubben gebruikt wordt\n",
    "\n",
    "#omgaan met train en test set"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b8f312320cd240106b9ea4d318428341e8727b3c7d5fc1f73cfe4a3d9868ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-E14Cnx23-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
