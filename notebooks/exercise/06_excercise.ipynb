{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "We will explore this dataset: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State#\n",
    "\n",
    "> All data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analysing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 07:13:30.913435: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-06 07:13:30.913473: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "data_dir = \"../../data/raw\"\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "datapath = tf.keras.utils.get_file(\n",
    "        \"eeg\", origin=url, untar=False, cache_dir=data_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the arff file with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "data = arff.loadarff(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/raw/datasets/eeg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a tuple of a description and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, tuple)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset: EEG_DATA\n",
       "\tAF3's type is numeric\n",
       "\tF7's type is numeric\n",
       "\tF3's type is numeric\n",
       "\tFC5's type is numeric\n",
       "\tT7's type is numeric\n",
       "\tP7's type is numeric\n",
       "\tO1's type is numeric\n",
       "\tO2's type is numeric\n",
       "\tP8's type is numeric\n",
       "\tT8's type is numeric\n",
       "\tFC6's type is numeric\n",
       "\tF4's type is numeric\n",
       "\tF8's type is numeric\n",
       "\tAF4's type is numeric\n",
       "\teyeDetection's type is nominal, range is ('0', '1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 15k observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000010vscode-remote?line=4'>5</a>\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m!=\u001b[39m \u001b[39m14\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000010vscode-remote?line=5'>6</a>\u001b[0m         observation\u001b[39m.\u001b[39mappend(i)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m observation \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor(observation)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m observation\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m torch\u001b[39m.\u001b[39mstack(observation)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "line = data[0][0]\n",
    "observation = []\n",
    "obs = []\n",
    "for index, i in enumerate(line):\n",
    "    if index != 14:\n",
    "        observation.append(i)\n",
    "observation = torch.Tensor(observation)\n",
    "observation\n",
    "\n",
    "torch.stack(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations are tuples of floats and a byte as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 0\n",
      "682 1\n",
      "464 0\n",
      "301 1\n",
      "537 0\n",
      "456 1\n",
      "266 0\n",
      "26 1\n",
      "414 0\n",
      "1009 1\n",
      "891 0\n",
      "683 1\n",
      "724 0\n",
      "2400 1\n",
      "2050 0\n",
      "970 1\n",
      "651 0\n",
      "42 1\n",
      "204 0\n",
      "51 1\n",
      "1188 0\n",
      "71 1\n",
      "669 0\n",
      "20 1\n",
      "torch.Size([20, 14])\n"
     ]
    }
   ],
   "source": [
    "first_label = int(data[0][0][14])\n",
    "label = first_label\n",
    "chunck = []\n",
    "chuncks = []\n",
    "for line in data[0]:\n",
    "    if int(line[14]) == label:\n",
    "        observation = []\n",
    "        for index, i in enumerate(line):\n",
    "            if index != 14:\n",
    "                observation.append(i)\n",
    "        observation = torch.Tensor(observation)\n",
    "        chunck.append(observation)\n",
    "    else:\n",
    "        chunck_tuple = (label, torch.stack(chunck))\n",
    "        chuncks.append(chunck_tuple)\n",
    "        label = int(line[14])\n",
    "        chunck = []\n",
    "        observation = []\n",
    "        for index, i in enumerate(line):\n",
    "            if index != 14:\n",
    "                observation.append(i)\n",
    "        observation = torch.Tensor(observation)\n",
    "chunck_tuple = (label, torch.stack(chunck))\n",
    "chuncks.append(chunck_tuple)\n",
    "\n",
    "\n",
    "def window(x: Tensor, n_time: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates and index that can be used to window a timeseries.\n",
    "    E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "    length 3 like this:\n",
    "\n",
    "    [0, 1, 2]\n",
    "    [1, 2, 3]\n",
    "    [2, 3, 4]\n",
    "    [3, 4, 5]\n",
    "\n",
    "    We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "    with the same length.\n",
    "    \"\"\"\n",
    "    n_window = len(x) - n_time + 1\n",
    "    time = torch.arange(0, n_time).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    return idx\n",
    "\n",
    "item = chuncks\n",
    "for item in chuncks:\n",
    "    print(len(item[1]), item[0])\n",
    "\n",
    "print(item[1].shape)\n",
    "y = item[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "upper bound and larger bound inconsistent with step sign",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000033vscode-remote?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m window(item[\u001b[39m1\u001b[39;49m], n_time \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000033vscode-remote?line=1'>2</a>\u001b[0m idx\n",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 15'\u001b[0m in \u001b[0;36mwindow\u001b[0;34m(x, n_time)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000034vscode-remote?line=14'>15</a>\u001b[0m n_window \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x) \u001b[39m-\u001b[39m n_time \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000034vscode-remote?line=15'>16</a>\u001b[0m time \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, n_time)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000034vscode-remote?line=16'>17</a>\u001b[0m window \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, n_window)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000034vscode-remote?line=17'>18</a>\u001b[0m idx \u001b[39m=\u001b[39m time \u001b[39m+\u001b[39m window\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000034vscode-remote?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m idx\n",
      "\u001b[0;31mRuntimeError\u001b[0m: upper bound and larger bound inconsistent with step sign"
     ]
    }
   ],
   "source": [
    "idx = window(item[1], n_time = 50)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def window(x: Tensor, n_time: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates and index that can be used to window a timeseries.\n",
    "    E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "    length 3 like this:\n",
    "\n",
    "    [0, 1, 2]\n",
    "    [1, 2, 3]\n",
    "    [2, 3, 4]\n",
    "    [3, 4, 5]\n",
    "\n",
    "    We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "    with the same length.\n",
    "    \"\"\"\n",
    "    n_window = len(x) - n_time + 1\n",
    "    time = torch.arange(0, n_time).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    return idx\n",
    "\n",
    "item[1].shape\n",
    "len(window(item[1], 19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 30\n",
    "count = 0\n",
    "for i in self.dataset:\n",
    "    lenght_observation = i[1].shape[0]\n",
    "    items_obs = lenght_observation-window_size+1\n",
    "    count += items_obs\n",
    "return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4487983978638184"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 45% of the data has closed eyes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises 1\n",
    "\n",
    "- create a get_eeg function that downloads the data to a given path\n",
    "- build a Dataset that yields a ($X, y$) tuple of tensors. $X$ should be sequential in time. Remember: a dataset should implement `__get_item__` and `__len__`.\n",
    "- note that you could model this as both a classification task, but also as a sequence-to-sequence task! For this excercise, make it a classification task with consecutive 0s or 1s only.\n",
    "- Note that, for a training task, a seq2seq model will probably be more realistic. However, the classification is a nice excercise because it is harder to set up.\n",
    "- figure out what the length distribution is of your dataset: how many timestamps do you have for every consecutive sequence of 0s and 1s? On average, median, min, max?\n",
    "- create a dataloader that yields timeseries with (batch, sequence_lenght). You can implement: windowed, padded and batched.\n",
    "    1. yielding a windowed item should be the easy level\n",
    "    2. yielding windowed and padded is medium level \n",
    "    3. yielding windowed, padded and batched is expert level, because the windowing will cause the timeseries to have different sizes. You will need to buffer before you can yield a batch.\n",
    "\n",
    "1. Upload this to github. \n",
    "2. Put your dev notebooks in a seperate folder\n",
    "3. Put all your functions in the src folder\n",
    "4. Use a formater & linter\n",
    "5. Add a single notebook, that sources the src folder. Indicate which level you got (1, 2 or 3)\n",
    "6. and that shows your dataloader works:\n",
    "    - it should not give errors because it runs out of data! Either let is stop by itself, or run forever.\n",
    "    - batchsize should be consistent (in case 1 and 2, batchsize is 1)\n",
    "    - sequence length is allowed to vary\n",
    "\n",
    "The first excercise is ex1, this one is ex2. You will get $max(ex1, average(ex1, ex2))$ as a final remark.\n",
    "Level 3 can get you an 11, because it exceeds expectation.\n",
    "\n",
    "# Excercise 2\n",
    "- build a Dataset that yields sequences of X, y. This time, y is a sequence and can contain both 0s and 1s\n",
    "- create a Dataloader with this\n",
    "- Test appropriate architectures (RNN, Attention)\n",
    "- for the loss, note that you will need a BCELoss instead of a CrossEntroyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 22,\n",
       " 20,\n",
       " 21,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 15,\n",
       " 8,\n",
       " 0,\n",
       " 18,\n",
       " 11,\n",
       " 17,\n",
       " 19,\n",
       " 14,\n",
       " 12,\n",
       " 13]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 09:26:34.176 | INFO     | __main__:get_eeg:26 - Data is downloaded to ../../data/raw/datasets/eeg.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[4438.4600, 4005.6399, 4287.6899,  ..., 4356.4102, 4811.2798,\n",
       "          4546.6699],\n",
       "         [4432.3101, 3998.4600, 4281.5400,  ..., 4351.2798, 4795.8999,\n",
       "          4533.8501],\n",
       "         [4427.1802, 3990.2600, 4281.0298,  ..., 4343.0801, 4783.5898,\n",
       "          4530.7700],\n",
       "         ...,\n",
       "         [4246.6699, 4002.0500, 4247.1802,  ..., 4263.5898, 4525.6401,\n",
       "          4283.0801],\n",
       "         [4249.2300, 4005.6399, 4245.1299,  ..., 4265.1299, 4533.3301,\n",
       "          4288.2100],\n",
       "         [4253.3301, 4015.8999, 4252.8198,  ..., 4267.1802, 4543.5898,\n",
       "          4301.0298]]),\n",
       " 1)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from loguru import logger\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from scipy.io import arff\n",
    "\n",
    "Tensor = torch.Tensor\n",
    "\n",
    "def get_eeg(data_dir: Path = \"../../data/raw\") -> Path:\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "    datapath = tf.keras.utils.get_file(\n",
    "        \"eeg\", origin=url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "    datapath = Path(datapath)\n",
    "    logger.info(f\"Data is downloaded to {datapath}.\")\n",
    "    return datapath\n",
    "\n",
    "class BaseDataset:\n",
    "    def __init__(self, datapath: Path):\n",
    "        self.path = datapath\n",
    "        self.data = self.process_data()\n",
    "\n",
    "        \n",
    "    def process_data(self) -> None:\n",
    "        data = arff.loadarff(self.path)\n",
    "        first_label = int(data[0][0][14])\n",
    "        label = first_label\n",
    "        chunck = []\n",
    "        chuncks = []\n",
    "        for line in data[0]:\n",
    "            if int(line[14]) == label:\n",
    "                observation = []\n",
    "                for index, i in enumerate(line):\n",
    "                    if index != 14:\n",
    "                        observation.append(i)\n",
    "                observation = torch.Tensor(observation)\n",
    "                chunck.append(observation)\n",
    "            else:\n",
    "                chunck_tuple = (label, torch.stack(chunck))\n",
    "                chuncks.append(chunck_tuple)\n",
    "                label = int(line[14])\n",
    "                chunck = []\n",
    "                observation = []\n",
    "                for index, i in enumerate(line):\n",
    "                    if index != 14:\n",
    "                        observation.append(i)\n",
    "                observation = torch.Tensor(observation)\n",
    "        chunck_tuple = (label, torch.stack(chunck))\n",
    "        chuncks.append(chunck_tuple)\n",
    "        return chuncks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        x = item[1]\n",
    "        y = item[0]\n",
    "        return x,y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        length = len(self.data)\n",
    "        return length\n",
    "\n",
    "dataloader = BaseDataset(datapath = get_eeg())\n",
    "dataloader.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (20, 487),\n",
       " 1: (11, 432),\n",
       " 2: (13, 783),\n",
       " 3: (16, 20),\n",
       " 4: (22, 409),\n",
       " 5: (17, 3),\n",
       " 6: (23, 0),\n",
       " 7: (5, 49),\n",
       " 8: (21, 8),\n",
       " 9: (12, 326),\n",
       " 10: (6, 28),\n",
       " 11: (16, 535),\n",
       " 12: (11, 541),\n",
       " 13: (19, 27),\n",
       " 14: (11, 260),\n",
       " 15: (19, 12),\n",
       " 16: (20, 237),\n",
       " 17: (6, 4),\n",
       " 18: (14, 1760),\n",
       " 19: (12, 61),\n",
       " 20: (17, 7),\n",
       " 21: (15, 412),\n",
       " 22: (5, 19),\n",
       " 23: (7, 1),\n",
       " 24: (8, 294),\n",
       " 25: (12, 354),\n",
       " 26: (16, 567),\n",
       " 27: (7, 4),\n",
       " 28: (4, 368),\n",
       " 29: (11, 204),\n",
       " 30: (19, 5),\n",
       " 31: (7, 4),\n",
       " 32: (6, 53),\n",
       " 33: (19, 7),\n",
       " 34: (3, 94),\n",
       " 35: (7, 0),\n",
       " 36: (2, 431),\n",
       " 37: (7, 6),\n",
       " 38: (18, 9),\n",
       " 39: (22, 41),\n",
       " 40: (20, 719),\n",
       " 41: (1, 59),\n",
       " 42: (22, 78),\n",
       " 43: (20, 303),\n",
       " 44: (8, 61),\n",
       " 45: (15, 159),\n",
       " 46: (11, 392),\n",
       " 47: (16, 425),\n",
       " 48: (16, 401),\n",
       " 49: (0, 65),\n",
       " 50: (6, 218),\n",
       " 51: (10, 150),\n",
       " 52: (12, 212),\n",
       " 53: (18, 171),\n",
       " 54: (22, 442),\n",
       " 55: (12, 632),\n",
       " 56: (12, 106),\n",
       " 57: (10, 288),\n",
       " 58: (7, 4),\n",
       " 59: (4, 426),\n",
       " 60: (8, 278),\n",
       " 61: (22, 90),\n",
       " 62: (18, 19),\n",
       " 63: (0, 167),\n",
       " 64: (17, 11),\n",
       " 65: (13, 839),\n",
       " 66: (14, 1776),\n",
       " 67: (10, 64),\n",
       " 68: (21, 3),\n",
       " 69: (23, 0),\n",
       " 70: (13, 1329),\n",
       " 71: (14, 46),\n",
       " 72: (15, 741),\n",
       " 73: (13, 874),\n",
       " 74: (2, 171),\n",
       " 75: (0, 166),\n",
       " 76: (10, 590),\n",
       " 77: (17, 3),\n",
       " 78: (3, 104),\n",
       " 79: (4, 21),\n",
       " 80: (21, 34),\n",
       " 81: (22, 364),\n",
       " 82: (17, 9),\n",
       " 83: (12, 435),\n",
       " 84: (5, 302),\n",
       " 85: (15, 501),\n",
       " 86: (9, 893),\n",
       " 87: (9, 741),\n",
       " 88: (9, 560),\n",
       " 89: (17, 13),\n",
       " 90: (18, 92),\n",
       " 91: (15, 715),\n",
       " 92: (17, 7),\n",
       " 93: (23, 0),\n",
       " 94: (3, 190),\n",
       " 95: (17, 5),\n",
       " 96: (17, 1),\n",
       " 97: (13, 659),\n",
       " 98: (4, 197),\n",
       " 99: (1, 304),\n",
       " 100: (16, 480),\n",
       " 101: (23, 0),\n",
       " 102: (8, 293),\n",
       " 103: (18, 18),\n",
       " 104: (1, 459),\n",
       " 105: (6, 94),\n",
       " 106: (4, 17),\n",
       " 107: (11, 145),\n",
       " 108: (7, 2),\n",
       " 109: (15, 160),\n",
       " 110: (16, 424),\n",
       " 111: (9, 165),\n",
       " 112: (23, 0),\n",
       " 113: (17, 8),\n",
       " 114: (11, 247),\n",
       " 115: (14, 1390),\n",
       " 116: (17, 15),\n",
       " 117: (19, 25),\n",
       " 118: (8, 58),\n",
       " 119: (7, 6),\n",
       " 120: (4, 354),\n",
       " 121: (14, 1940),\n",
       " 122: (2, 379),\n",
       " 123: (5, 141),\n",
       " 124: (17, 20),\n",
       " 125: (21, 15),\n",
       " 126: (19, 31),\n",
       " 127: (1, 277),\n",
       " 128: (20, 1029),\n",
       " 129: (2, 6),\n",
       " 130: (3, 96),\n",
       " 131: (18, 124),\n",
       " 132: (19, 7),\n",
       " 133: (19, 31),\n",
       " 134: (19, 4),\n",
       " 135: (21, 48),\n",
       " 136: (7, 1),\n",
       " 137: (5, 293),\n",
       " 138: (20, 527),\n",
       " 139: (12, 515),\n",
       " 140: (4, 305),\n",
       " 141: (5, 156),\n",
       " 142: (22, 226),\n",
       " 143: (12, 270),\n",
       " 144: (11, 503),\n",
       " 145: (20, 95),\n",
       " 146: (17, 16),\n",
       " 147: (9, 308),\n",
       " 148: (0, 45),\n",
       " 149: (16, 1),\n",
       " 150: (14, 501),\n",
       " 151: (15, 553),\n",
       " 152: (12, 365),\n",
       " 153: (3, 11),\n",
       " 154: (9, 155),\n",
       " 155: (6, 228),\n",
       " 156: (16, 95),\n",
       " 157: (13, 642),\n",
       " 158: (12, 289),\n",
       " 159: (12, 385),\n",
       " 160: (5, 313),\n",
       " 161: (4, 365),\n",
       " 162: (7, 6),\n",
       " 163: (3, 100),\n",
       " 164: (22, 23),\n",
       " 165: (12, 74),\n",
       " 166: (2, 282),\n",
       " 167: (1, 488),\n",
       " 168: (0, 9),\n",
       " 169: (7, 5),\n",
       " 170: (11, 222),\n",
       " 171: (9, 630),\n",
       " 172: (14, 69),\n",
       " 173: (20, 130),\n",
       " 174: (14, 1887),\n",
       " 175: (6, 144),\n",
       " 176: (11, 343),\n",
       " 177: (7, 3),\n",
       " 178: (18, 183),\n",
       " 179: (10, 775),\n",
       " 180: (14, 201),\n",
       " 181: (15, 858),\n",
       " 182: (12, 310),\n",
       " 183: (11, 105),\n",
       " 184: (15, 914),\n",
       " 185: (20, 689),\n",
       " 186: (4, 36),\n",
       " 187: (6, 58),\n",
       " 188: (23, 0),\n",
       " 189: (11, 59),\n",
       " 190: (19, 0),\n",
       " 191: (8, 311),\n",
       " 192: (2, 262),\n",
       " 193: (22, 114),\n",
       " 194: (23, 0),\n",
       " 195: (6, 25),\n",
       " 196: (19, 15),\n",
       " 197: (23, 0),\n",
       " 198: (15, 787),\n",
       " 199: (0, 90),\n",
       " 200: (14, 1116),\n",
       " 201: (13, 1516),\n",
       " 202: (0, 8),\n",
       " 203: (18, 130),\n",
       " 204: (3, 155),\n",
       " 205: (12, 168),\n",
       " 206: (7, 6),\n",
       " 207: (22, 600),\n",
       " 208: (0, 136),\n",
       " 209: (15, 167),\n",
       " 210: (8, 268),\n",
       " 211: (4, 188),\n",
       " 212: (21, 22),\n",
       " 213: (8, 374),\n",
       " 214: (18, 136),\n",
       " 215: (14, 817),\n",
       " 216: (19, 21),\n",
       " 217: (4, 417),\n",
       " 218: (21, 26),\n",
       " 219: (2, 336),\n",
       " 220: (3, 7),\n",
       " 221: (17, 19),\n",
       " 222: (15, 594),\n",
       " 223: (17, 10),\n",
       " 224: (4, 83),\n",
       " 225: (21, 19),\n",
       " 226: (16, 488),\n",
       " 227: (15, 43),\n",
       " 228: (11, 340),\n",
       " 229: (10, 643),\n",
       " 230: (8, 46),\n",
       " 231: (23, 0),\n",
       " 232: (14, 1249),\n",
       " 233: (19, 29),\n",
       " 234: (7, 0),\n",
       " 235: (8, 338),\n",
       " 236: (22, 198),\n",
       " 237: (13, 1977),\n",
       " 238: (2, 405),\n",
       " 239: (21, 25),\n",
       " 240: (21, 50),\n",
       " 241: (10, 509),\n",
       " 242: (3, 246),\n",
       " 243: (14, 69),\n",
       " 244: (11, 167),\n",
       " 245: (7, 6),\n",
       " 246: (7, 0),\n",
       " 247: (23, 0),\n",
       " 248: (0, 72),\n",
       " 249: (3, 101),\n",
       " 250: (6, 228),\n",
       " 251: (13, 1301),\n",
       " 252: (3, 105),\n",
       " 253: (13, 1273),\n",
       " 254: (22, 262),\n",
       " 255: (9, 806),\n",
       " 256: (10, 139),\n",
       " 257: (12, 442),\n",
       " 258: (4, 90),\n",
       " 259: (20, 250),\n",
       " 260: (9, 877),\n",
       " 261: (4, 294),\n",
       " 262: (10, 209),\n",
       " 263: (4, 404),\n",
       " 264: (0, 87),\n",
       " 265: (16, 155),\n",
       " 266: (3, 83),\n",
       " 267: (22, 26),\n",
       " 268: (3, 103),\n",
       " 269: (13, 1783),\n",
       " 270: (9, 932),\n",
       " 271: (12, 63),\n",
       " 272: (11, 538),\n",
       " 273: (8, 115),\n",
       " 274: (3, 80),\n",
       " 275: (21, 47),\n",
       " 276: (5, 102),\n",
       " 277: (22, 112),\n",
       " 278: (11, 87),\n",
       " 279: (19, 26),\n",
       " 280: (0, 72),\n",
       " 281: (8, 282),\n",
       " 282: (8, 195),\n",
       " 283: (11, 447),\n",
       " 284: (9, 630),\n",
       " 285: (2, 331),\n",
       " 286: (13, 880),\n",
       " 287: (20, 750),\n",
       " 288: (14, 1903),\n",
       " 289: (8, 46),\n",
       " 290: (11, 294),\n",
       " 291: (2, 378),\n",
       " 292: (3, 232),\n",
       " 293: (8, 236),\n",
       " 294: (10, 533),\n",
       " 295: (15, 881),\n",
       " 296: (4, 50),\n",
       " 297: (23, 0),\n",
       " 298: (9, 988),\n",
       " 299: (23, 0),\n",
       " 300: (17, 12),\n",
       " 301: (15, 578),\n",
       " 302: (21, 15),\n",
       " 303: (7, 4),\n",
       " 304: (2, 273),\n",
       " 305: (22, 222),\n",
       " 306: (13, 844),\n",
       " 307: (7, 3),\n",
       " 308: (4, 502),\n",
       " 309: (4, 116),\n",
       " 310: (4, 433),\n",
       " 311: (17, 20),\n",
       " 312: (15, 678),\n",
       " 313: (18, 37),\n",
       " 314: (22, 483),\n",
       " 315: (17, 17),\n",
       " 316: (23, 0),\n",
       " 317: (13, 2243),\n",
       " 318: (16, 424),\n",
       " 319: (14, 335),\n",
       " 320: (14, 1153),\n",
       " 321: (22, 529),\n",
       " 322: (1, 305),\n",
       " 323: (18, 102),\n",
       " 324: (21, 16),\n",
       " 325: (14, 1724),\n",
       " 326: (13, 1346),\n",
       " 327: (18, 49),\n",
       " 328: (1, 45),\n",
       " 329: (7, 3),\n",
       " 330: (1, 577),\n",
       " 331: (8, 160),\n",
       " 332: (18, 25),\n",
       " 333: (4, 251),\n",
       " 334: (21, 23),\n",
       " 335: (12, 218),\n",
       " 336: (18, 24),\n",
       " 337: (18, 105),\n",
       " 338: (6, 72),\n",
       " 339: (16, 347),\n",
       " 340: (14, 883),\n",
       " 341: (12, 652),\n",
       " 342: (4, 409),\n",
       " 343: (4, 215),\n",
       " 344: (1, 618),\n",
       " 345: (5, 126),\n",
       " 346: (21, 30),\n",
       " 347: (11, 120),\n",
       " 348: (6, 100),\n",
       " 349: (21, 3),\n",
       " 350: (21, 22),\n",
       " 351: (23, 0),\n",
       " 352: (18, 167),\n",
       " 353: (11, 568),\n",
       " 354: (5, 427),\n",
       " 355: (21, 12),\n",
       " 356: (18, 121),\n",
       " 357: (12, 303),\n",
       " 358: (9, 213),\n",
       " 359: (0, 33),\n",
       " 360: (1, 455),\n",
       " 361: (23, 0),\n",
       " 362: (3, 266),\n",
       " 363: (2, 325),\n",
       " 364: (11, 257),\n",
       " 365: (11, 605),\n",
       " 366: (0, 35),\n",
       " 367: (5, 139),\n",
       " 368: (18, 105),\n",
       " 369: (6, 84),\n",
       " 370: (11, 467),\n",
       " 371: (8, 186),\n",
       " 372: (22, 127),\n",
       " 373: (16, 194),\n",
       " 374: (7, 2),\n",
       " 375: (19, 10),\n",
       " 376: (0, 9),\n",
       " 377: (13, 1380),\n",
       " 378: (14, 1998),\n",
       " 379: (11, 353),\n",
       " 380: (10, 351),\n",
       " 381: (23, 0),\n",
       " 382: (6, 108),\n",
       " 383: (17, 6),\n",
       " 384: (9, 201),\n",
       " 385: (0, 96),\n",
       " 386: (2, 390),\n",
       " 387: (16, 412),\n",
       " 388: (4, 413),\n",
       " 389: (22, 64),\n",
       " 390: (8, 309),\n",
       " 391: (20, 382),\n",
       " 392: (19, 9),\n",
       " 393: (6, 226),\n",
       " 394: (13, 324),\n",
       " 395: (22, 193),\n",
       " 396: (8, 301),\n",
       " 397: (10, 627),\n",
       " 398: (3, 213),\n",
       " 399: (4, 467),\n",
       " 400: (4, 500),\n",
       " 401: (2, 259),\n",
       " 402: (2, 157),\n",
       " 403: (4, 300),\n",
       " 404: (21, 16),\n",
       " 405: (3, 12),\n",
       " 406: (18, 84),\n",
       " 407: (2, 24),\n",
       " 408: (8, 301),\n",
       " 409: (10, 827),\n",
       " 410: (3, 143),\n",
       " 411: (10, 104),\n",
       " 412: (13, 1106),\n",
       " 413: (11, 577),\n",
       " 414: (20, 589),\n",
       " 415: (0, 104),\n",
       " 416: (22, 125),\n",
       " 417: (15, 674),\n",
       " 418: (21, 33),\n",
       " 419: (14, 1022),\n",
       " 420: (17, 17),\n",
       " 421: (16, 17),\n",
       " 422: (6, 134),\n",
       " 423: (23, 0),\n",
       " 424: (18, 44),\n",
       " 425: (23, 0),\n",
       " 426: (9, 176),\n",
       " 427: (15, 512),\n",
       " 428: (5, 407),\n",
       " 429: (16, 268),\n",
       " 430: (7, 1),\n",
       " 431: (14, 867),\n",
       " 432: (12, 192),\n",
       " 433: (1, 430),\n",
       " 434: (20, 24),\n",
       " 435: (6, 40),\n",
       " 436: (5, 397),\n",
       " 437: (21, 32),\n",
       " 438: (18, 139),\n",
       " 439: (0, 48),\n",
       " 440: (2, 393),\n",
       " 441: (20, 921),\n",
       " 442: (21, 50),\n",
       " 443: (7, 4),\n",
       " 444: (1, 159),\n",
       " 445: (21, 12),\n",
       " 446: (7, 6),\n",
       " 447: (6, 119),\n",
       " 448: (2, 155),\n",
       " 449: (15, 438),\n",
       " 450: (1, 212),\n",
       " 451: (0, 140),\n",
       " 452: (10, 463),\n",
       " 453: (7, 3),\n",
       " 454: (10, 848),\n",
       " 455: (2, 442),\n",
       " 456: (21, 34),\n",
       " 457: (23, 0),\n",
       " 458: (21, 11),\n",
       " 459: (0, 25),\n",
       " 460: (19, 27),\n",
       " 461: (17, 11),\n",
       " 462: (18, 87),\n",
       " 463: (4, 163),\n",
       " 464: (17, 18),\n",
       " 465: (4, 433),\n",
       " 466: (15, 42),\n",
       " 467: (17, 16),\n",
       " 468: (20, 168),\n",
       " 469: (15, 738),\n",
       " 470: (2, 419),\n",
       " 471: (8, 228),\n",
       " 472: (17, 1),\n",
       " 473: (13, 176),\n",
       " 474: (6, 97),\n",
       " 475: (2, 277),\n",
       " 476: (1, 482),\n",
       " 477: (22, 407),\n",
       " 478: (20, 392),\n",
       " 479: (2, 75),\n",
       " 480: (7, 0),\n",
       " 481: (7, 4),\n",
       " 482: (13, 212),\n",
       " 483: (9, 733),\n",
       " 484: (22, 577),\n",
       " 485: (14, 684),\n",
       " 486: (20, 337),\n",
       " 487: (8, 136),\n",
       " 488: (2, 176),\n",
       " 489: (21, 22),\n",
       " 490: (3, 159),\n",
       " 491: (7, 6),\n",
       " 492: (2, 87),\n",
       " 493: (13, 632),\n",
       " 494: (18, 20),\n",
       " 495: (18, 88),\n",
       " 496: (17, 11),\n",
       " 497: (6, 126),\n",
       " 498: (12, 217),\n",
       " 499: (4, 56),\n",
       " 500: (14, 557),\n",
       " 501: (4, 272),\n",
       " 502: (21, 47),\n",
       " 503: (12, 586),\n",
       " 504: (21, 23),\n",
       " 505: (19, 17),\n",
       " 506: (0, 16),\n",
       " 507: (20, 1131),\n",
       " 508: (21, 22),\n",
       " 509: (22, 300),\n",
       " 510: (8, 133),\n",
       " 511: (0, 43),\n",
       " 512: (11, 108),\n",
       " 513: (23, 0),\n",
       " 514: (2, 44),\n",
       " 515: (11, 15),\n",
       " 516: (8, 53),\n",
       " 517: (20, 712),\n",
       " 518: (1, 540),\n",
       " 519: (3, 267),\n",
       " 520: (11, 199),\n",
       " 521: (2, 223),\n",
       " 522: (21, 18),\n",
       " 523: (6, 103),\n",
       " 524: (17, 2),\n",
       " 525: (8, 136),\n",
       " 526: (11, 618),\n",
       " 527: (0, 144),\n",
       " 528: (1, 104),\n",
       " 529: (4, 17),\n",
       " 530: (8, 166),\n",
       " 531: (6, 112),\n",
       " 532: (11, 34),\n",
       " 533: (16, 409),\n",
       " 534: (13, 793),\n",
       " 535: (1, 327),\n",
       " 536: (18, 140),\n",
       " 537: (1, 382),\n",
       " 538: (17, 7),\n",
       " 539: (4, 228),\n",
       " 540: (14, 739),\n",
       " 541: (1, 6),\n",
       " 542: (23, 0),\n",
       " 543: (16, 610),\n",
       " 544: (11, 49),\n",
       " 545: (2, 343),\n",
       " 546: (14, 84),\n",
       " 547: (0, 24),\n",
       " 548: (18, 77),\n",
       " 549: (6, 87),\n",
       " 550: (13, 1421),\n",
       " 551: (12, 6),\n",
       " 552: (10, 348),\n",
       " 553: (6, 115),\n",
       " 554: (23, 0),\n",
       " 555: (9, 657),\n",
       " 556: (13, 248),\n",
       " 557: (16, 279),\n",
       " 558: (20, 382),\n",
       " 559: (10, 509),\n",
       " 560: (16, 578),\n",
       " 561: (3, 36),\n",
       " 562: (10, 8),\n",
       " 563: (8, 112),\n",
       " 564: (7, 6),\n",
       " 565: (0, 28),\n",
       " 566: (13, 1069),\n",
       " 567: (3, 122),\n",
       " 568: (18, 156),\n",
       " 569: (7, 2),\n",
       " 570: (22, 201),\n",
       " 571: (11, 519),\n",
       " 572: (12, 100),\n",
       " 573: (3, 159),\n",
       " 574: (4, 134),\n",
       " 575: (20, 477),\n",
       " 576: (22, 254),\n",
       " 577: (13, 122),\n",
       " 578: (8, 151),\n",
       " 579: (17, 0),\n",
       " 580: (9, 743),\n",
       " 581: (0, 87),\n",
       " 582: (19, 7),\n",
       " 583: (3, 170),\n",
       " 584: (13, 1790),\n",
       " 585: (6, 202),\n",
       " 586: (7, 5),\n",
       " 587: (21, 37),\n",
       " 588: (19, 20),\n",
       " 589: (8, 309),\n",
       " 590: (11, 608),\n",
       " 591: (5, 27),\n",
       " 592: (6, 36),\n",
       " 593: (10, 591),\n",
       " 594: (19, 31),\n",
       " 595: (5, 320),\n",
       " 596: (1, 382),\n",
       " 597: (4, 50),\n",
       " 598: (20, 820),\n",
       " 599: (14, 1576),\n",
       " 600: (18, 131),\n",
       " 601: (7, 3),\n",
       " 602: (0, 118),\n",
       " 603: (17, 14),\n",
       " 604: (23, 0),\n",
       " 605: (13, 970),\n",
       " 606: (0, 42),\n",
       " 607: (17, 6),\n",
       " 608: (18, 35),\n",
       " 609: (13, 2323),\n",
       " 610: (20, 285),\n",
       " 611: (18, 146),\n",
       " 612: (17, 4),\n",
       " 613: (8, 370),\n",
       " 614: (1, 204),\n",
       " 615: (12, 379),\n",
       " 616: (14, 1513),\n",
       " 617: (20, 517),\n",
       " 618: (0, 79),\n",
       " 619: (20, 1114),\n",
       " 620: (20, 444),\n",
       " 621: (21, 22),\n",
       " 622: (5, 63),\n",
       " 623: (7, 5),\n",
       " 624: (7, 0),\n",
       " 625: (8, 114),\n",
       " 626: (0, 95),\n",
       " 627: (18, 103),\n",
       " 628: (22, 139),\n",
       " 629: (18, 29),\n",
       " 630: (17, 15),\n",
       " 631: (0, 141),\n",
       " 632: (7, 1),\n",
       " 633: (2, 163),\n",
       " 634: (14, 1942),\n",
       " 635: (10, 341),\n",
       " 636: (4, 289),\n",
       " 637: (14, 1049),\n",
       " 638: (5, 85),\n",
       " 639: (18, 145),\n",
       " 640: (10, 65),\n",
       " 641: (4, 386),\n",
       " 642: (19, 18),\n",
       " 643: (0, 103),\n",
       " 644: (9, 325),\n",
       " 645: (2, 13),\n",
       " 646: (16, 133),\n",
       " 647: (16, 603),\n",
       " 648: (8, 344),\n",
       " 649: (20, 521),\n",
       " 650: (20, 935),\n",
       " 651: (15, 588),\n",
       " 652: (21, 33),\n",
       " 653: (23, 0),\n",
       " 654: (20, 472),\n",
       " 655: (11, 420),\n",
       " 656: (9, 329),\n",
       " 657: (6, 134),\n",
       " 658: (10, 631),\n",
       " 659: (13, 12),\n",
       " 660: (0, 107),\n",
       " 661: (15, 670),\n",
       " 662: (20, 444),\n",
       " 663: (14, 744),\n",
       " 664: (0, 25),\n",
       " 665: (2, 379),\n",
       " 666: (4, 64),\n",
       " 667: (15, 203),\n",
       " 668: (7, 5),\n",
       " 669: (11, 364),\n",
       " 670: (2, 15),\n",
       " 671: (10, 349),\n",
       " 672: (21, 21),\n",
       " 673: (15, 611),\n",
       " 674: (11, 629),\n",
       " 675: (21, 36),\n",
       " 676: (4, 445),\n",
       " 677: (3, 249),\n",
       " 678: (1, 333),\n",
       " 679: (3, 238),\n",
       " 680: (0, 132),\n",
       " 681: (10, 122),\n",
       " 682: (1, 337),\n",
       " 683: (12, 567),\n",
       " 684: (22, 488),\n",
       " 685: (16, 459),\n",
       " 686: (23, 0),\n",
       " 687: (0, 63),\n",
       " 688: (9, 366),\n",
       " 689: (14, 1069),\n",
       " 690: (23, 0),\n",
       " 691: (6, 184),\n",
       " 692: (6, 3),\n",
       " 693: (6, 96),\n",
       " 694: (1, 451),\n",
       " 695: (13, 1595),\n",
       " 696: (18, 38),\n",
       " 697: (12, 71),\n",
       " 698: (10, 293),\n",
       " 699: (0, 114),\n",
       " 700: (1, 543),\n",
       " 701: (2, 330),\n",
       " 702: (2, 182),\n",
       " 703: (19, 7),\n",
       " 704: (23, 0),\n",
       " 705: (21, 34),\n",
       " 706: (4, 438),\n",
       " 707: (19, 27),\n",
       " 708: (4, 198),\n",
       " 709: (9, 620),\n",
       " 710: (10, 300),\n",
       " 711: (21, 16),\n",
       " 712: (13, 1337),\n",
       " 713: (6, 66),\n",
       " 714: (15, 385),\n",
       " 715: (21, 8),\n",
       " 716: (11, 447),\n",
       " 717: (11, 470),\n",
       " 718: (11, 422),\n",
       " 719: (21, 14),\n",
       " 720: (8, 305),\n",
       " 721: (8, 216),\n",
       " 722: (12, 293),\n",
       " 723: (12, 330),\n",
       " 724: (2, 159),\n",
       " 725: (10, 557),\n",
       " 726: (7, 4),\n",
       " 727: (20, 583),\n",
       " 728: (20, 157),\n",
       " 729: (19, 10),\n",
       " 730: (15, 337),\n",
       " 731: (20, 31),\n",
       " 732: (22, 303),\n",
       " 733: (10, 231),\n",
       " 734: (1, 200),\n",
       " 735: (10, 58),\n",
       " 736: (16, 235),\n",
       " 737: (5, 99),\n",
       " 738: (17, 21),\n",
       " 739: (17, 5),\n",
       " 740: (22, 172),\n",
       " 741: (2, 343),\n",
       " 742: (11, 635),\n",
       " 743: (15, 142),\n",
       " 744: (21, 13),\n",
       " 745: (22, 228),\n",
       " 746: (11, 65),\n",
       " 747: (2, 16),\n",
       " 748: (20, 802),\n",
       " 749: (16, 259),\n",
       " 750: (17, 18),\n",
       " 751: (15, 308),\n",
       " 752: (3, 166),\n",
       " 753: (16, 245),\n",
       " 754: (8, 255),\n",
       " 755: (20, 589),\n",
       " 756: (12, 638),\n",
       " 757: (21, 43),\n",
       " 758: (19, 6),\n",
       " 759: (23, 0),\n",
       " 760: (21, 16),\n",
       " 761: (10, 783),\n",
       " 762: (16, 587),\n",
       " 763: (7, 6),\n",
       " 764: (0, 132),\n",
       " 765: (9, 451),\n",
       " 766: (3, 153),\n",
       " 767: (19, 18),\n",
       " 768: (5, 116),\n",
       " 769: (20, 515),\n",
       " 770: (6, 225),\n",
       " 771: (19, 0),\n",
       " 772: (8, 7),\n",
       " 773: (5, 243),\n",
       " 774: (13, 995),\n",
       " 775: (13, 232),\n",
       " 776: (19, 25),\n",
       " 777: (20, 31),\n",
       " 778: (5, 63),\n",
       " 779: (9, 317),\n",
       " 780: (20, 892),\n",
       " 781: (12, 477),\n",
       " 782: (3, 128),\n",
       " 783: (4, 320),\n",
       " 784: (18, 134),\n",
       " 785: (19, 15),\n",
       " 786: (13, 694),\n",
       " 787: (7, 1),\n",
       " 788: (18, 179),\n",
       " 789: (22, 562),\n",
       " 790: (4, 114),\n",
       " 791: (23, 0),\n",
       " 792: (7, 2),\n",
       " 793: (8, 169),\n",
       " 794: (20, 950),\n",
       " 795: (9, 940),\n",
       " 796: (13, 365),\n",
       " 797: (5, 241),\n",
       " 798: (9, 540),\n",
       " 799: (23, 0),\n",
       " 800: (4, 515),\n",
       " 801: (8, 32),\n",
       " 802: (21, 5),\n",
       " 803: (23, 0),\n",
       " 804: (8, 307),\n",
       " 805: (1, 317),\n",
       " 806: (19, 9),\n",
       " 807: (13, 1273),\n",
       " 808: (20, 1157),\n",
       " 809: (21, 44),\n",
       " 810: (17, 22),\n",
       " 811: (13, 1153),\n",
       " 812: (1, 586),\n",
       " 813: (18, 110),\n",
       " 814: (23, 0),\n",
       " 815: (19, 8),\n",
       " 816: (8, 317),\n",
       " 817: (10, 453),\n",
       " 818: (12, 113),\n",
       " 819: (1, 660),\n",
       " 820: (10, 387),\n",
       " 821: (7, 6),\n",
       " 822: (1, 585),\n",
       " 823: (9, 337),\n",
       " 824: (1, 67),\n",
       " 825: (5, 206),\n",
       " 826: (14, 518),\n",
       " 827: (3, 159),\n",
       " 828: (20, 1101),\n",
       " 829: (3, 258),\n",
       " 830: (21, 28),\n",
       " 831: (23, 0),\n",
       " 832: (10, 333),\n",
       " 833: (0, 158),\n",
       " 834: (4, 170),\n",
       " 835: (17, 11),\n",
       " 836: (2, 270),\n",
       " 837: (2, 316),\n",
       " 838: (9, 897),\n",
       " 839: (15, 69),\n",
       " 840: (15, 838),\n",
       " 841: (17, 10),\n",
       " 842: (23, 0),\n",
       " 843: (9, 467),\n",
       " 844: (14, 815),\n",
       " 845: (17, 6),\n",
       " 846: (8, 6),\n",
       " 847: (13, 2206),\n",
       " 848: (11, 132),\n",
       " 849: (4, 53),\n",
       " 850: (11, 483),\n",
       " 851: (9, 644),\n",
       " 852: (1, 387),\n",
       " 853: (1, 580),\n",
       " 854: (7, 2),\n",
       " 855: (3, 261),\n",
       " 856: (23, 0),\n",
       " 857: (1, 79),\n",
       " 858: (16, 161),\n",
       " 859: (7, 3),\n",
       " 860: (20, 101),\n",
       " 861: (18, 25),\n",
       " 862: (13, 243),\n",
       " 863: (16, 527),\n",
       " 864: (9, 605),\n",
       " 865: (8, 259),\n",
       " 866: (12, 63),\n",
       " 867: (15, 932),\n",
       " 868: (7, 5),\n",
       " 869: (16, 404),\n",
       " 870: (9, 658),\n",
       " 871: (7, 2),\n",
       " 872: (19, 22),\n",
       " 873: (7, 1),\n",
       " 874: (1, 412),\n",
       " 875: (23, 0),\n",
       " 876: (16, 476),\n",
       " 877: (8, 342),\n",
       " 878: (10, 743),\n",
       " 879: (22, 154),\n",
       " 880: (22, 484),\n",
       " 881: (12, 361),\n",
       " 882: (0, 74),\n",
       " 883: (18, 104),\n",
       " 884: (0, 39),\n",
       " 885: (19, 17),\n",
       " 886: (0, 98),\n",
       " 887: (18, 42),\n",
       " 888: (9, 479),\n",
       " 889: (19, 15),\n",
       " 890: (4, 325),\n",
       " 891: (4, 124),\n",
       " 892: (21, 47),\n",
       " 893: (19, 4),\n",
       " 894: (13, 645),\n",
       " 895: (10, 814),\n",
       " 896: (10, 721),\n",
       " 897: (10, 122),\n",
       " 898: (16, 222),\n",
       " 899: (2, 345),\n",
       " 900: (9, 938),\n",
       " 901: (2, 72),\n",
       " 902: (20, 181),\n",
       " 903: (20, 92),\n",
       " 904: (22, 71),\n",
       " 905: (14, 524),\n",
       " 906: (23, 0),\n",
       " 907: (4, 438),\n",
       " 908: (4, 343),\n",
       " 909: (2, 1),\n",
       " 910: (7, 5),\n",
       " 911: (5, 186),\n",
       " 912: (11, 554),\n",
       " 913: (23, 0),\n",
       " 914: (7, 3),\n",
       " 915: (13, 1964),\n",
       " 916: (13, 1536),\n",
       " 917: (13, 1372),\n",
       " 918: (4, 156),\n",
       " 919: (4, 231),\n",
       " 920: (6, 99),\n",
       " 921: (17, 0),\n",
       " 922: (0, 29),\n",
       " 923: (8, 268),\n",
       " 924: (15, 948),\n",
       " 925: (22, 187),\n",
       " 926: (15, 429),\n",
       " 927: (14, 2003),\n",
       " 928: (7, 3),\n",
       " 929: (13, 2324),\n",
       " 930: (12, 85),\n",
       " 931: (15, 403),\n",
       " 932: (16, 447),\n",
       " 933: (11, 565),\n",
       " 934: (8, 70),\n",
       " 935: (0, 52),\n",
       " 936: (19, 12),\n",
       " 937: (8, 151),\n",
       " 938: (11, 476),\n",
       " 939: (5, 359),\n",
       " 940: (0, 161),\n",
       " 941: (12, 329),\n",
       " 942: (4, 16),\n",
       " 943: (11, 494),\n",
       " 944: (7, 5),\n",
       " 945: (2, 253),\n",
       " 946: (9, 456),\n",
       " 947: (12, 300),\n",
       " 948: (17, 15),\n",
       " 949: (19, 30),\n",
       " 950: (13, 1155),\n",
       " 951: (10, 653),\n",
       " 952: (19, 2),\n",
       " 953: (13, 2099),\n",
       " 954: (14, 2002),\n",
       " 955: (16, 239),\n",
       " 956: (11, 621),\n",
       " 957: (8, 325),\n",
       " 958: (12, 420),\n",
       " 959: (4, 430),\n",
       " 960: (11, 481),\n",
       " 961: (23, 0),\n",
       " 962: (12, 590),\n",
       " 963: (15, 477),\n",
       " 964: (1, 226),\n",
       " 965: (3, 41),\n",
       " 966: (14, 1308),\n",
       " 967: (0, 18),\n",
       " 968: (12, 350),\n",
       " 969: (21, 37),\n",
       " 970: (14, 580),\n",
       " 971: (9, 965),\n",
       " 972: (20, 569),\n",
       " 973: (20, 772),\n",
       " 974: (11, 142),\n",
       " 975: (4, 94),\n",
       " 976: (3, 174),\n",
       " 977: (15, 262),\n",
       " 978: (14, 921),\n",
       " 979: (12, 608),\n",
       " 980: (4, 408),\n",
       " 981: (11, 402),\n",
       " 982: (4, 6),\n",
       " 983: (21, 18),\n",
       " 984: (2, 127),\n",
       " 985: (21, 9),\n",
       " 986: (23, 0),\n",
       " 987: (15, 529),\n",
       " 988: (23, 0),\n",
       " 989: (13, 339),\n",
       " 990: (23, 0),\n",
       " 991: (8, 355),\n",
       " 992: (10, 398),\n",
       " 993: (0, 93),\n",
       " 994: (7, 1),\n",
       " 995: (23, 0),\n",
       " 996: (8, 303),\n",
       " 997: (12, 529),\n",
       " 998: (3, 198),\n",
       " 999: (22, 69),\n",
       " ...}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listpossibilities = [(0, 168), (1, 662), (2, 444), (3, 281), (4, 517), (5, 436), (6, 246), (7, 6), (8, 394), (9, 989), (10, 871), (11, 663), (12, 704), (13, 2380), (14, 2030), (15, 950), (16, 631), (17, 22), (18, 184), (19, 31), (20, 1168), (21, 51), (22, 649), (23, 0)]\n",
    "listpossibilities\n",
    "\n",
    "count = 0\n",
    "window_size =10\n",
    "dict_iterator = {}\n",
    "\n",
    "for i in listpossibilities:\n",
    "    windowedItems = i[1] -window_size + 1\n",
    "    count += windowedItems\n",
    "        \n",
    "\n",
    "\n",
    "for item in range(count):\n",
    "    obs = random.randint(0,23)\n",
    "    dict_iterator[item] = (obs, random.randint(0, listpossibilities[obs][1]))\n",
    "\n",
    "dict_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-06 11:17:11.622 | INFO     | __main__:get_eeg:26 - Data is downloaded to ../../data/raw/datasets/eeg.\n"
     ]
    }
   ],
   "source": [
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        self.dataset = dataset #set dataset\n",
    "        self.batchsize = batchsize #set batchsize\n",
    "        self.window_size = window_size #set windowsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        window_size = self.window_size\n",
    "        count = 0 #init count\n",
    "        for i in self.dataset: #loop through all observations\n",
    "            lenght_observation = i[0].shape[0] #get nr of rows in the observation\n",
    "            items_obs = lenght_observation-window_size+1 #get possible nr of windows from observation\n",
    "            count += items_obs #increment count\n",
    "        return count #return max nr of items\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator: \n",
    "        length = len(self) #get the max nr of iterations\n",
    "        self.dict_iterator = {} #init dict to store indexes \n",
    "        lengthobs = len(self.dataset) #get nr of observations\n",
    "        index_tuples = [] #to store max nr tuples in\n",
    "        for i in range(lengthobs):\n",
    "            x,y = dataset.__getitem__(i) \n",
    "            lenght_item = x.shape[0]-self.window_size+1 \n",
    "            index_tuples.append((i, lenght_item)) \n",
    "        for item in range(count):\n",
    "            obs = random.randint(0,23)\n",
    "            self.dict_iterator[item] = (obs, random.randint(0, index_tuples[obs][1]))\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        X, Y = self.batchloop()  # noqa N806\n",
    "        return torch.tensor(X), torch.tensor(Y)\n",
    "\n",
    "    def window(self, x: Tensor, n_time: int) -> Tensor: #function to get windowed items from observation\n",
    "        \"\"\"\n",
    "        Generates and index that can be used to window a timeseries.\n",
    "        E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "        length 3 like this:\n",
    "\n",
    "        [0, 1, 2]\n",
    "        [1, 2, 3]\n",
    "        [2, 3, 4]\n",
    "        [3, 4, 5]\n",
    "\n",
    "        We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "        with the same length.\n",
    "        \"\"\"\n",
    "        n_window = len(x) - n_time + 1\n",
    "        time = torch.arange(0, n_time).reshape(1, -1)\n",
    "        window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "        idx = time + window\n",
    "        return idx\n",
    "\n",
    "    def get_windowed_item(self):\n",
    "        print(self.index)\n",
    "        window_size = self.window_size #get window size\n",
    "        itemIndexes = self.dict_iterator[self.index]\n",
    "        print(itemIndexes)\n",
    "        x,y = self.dataset.__getitem__(itemIndexes[0]) #get the item and store in x and y\n",
    "        if self.window_size > int(x.shape[0]): #if the window size is larger than the nr of lines in observation\n",
    "            idx = self.window(x, x.shape[0]) #take the whole item\n",
    "        else: # if the window size is smaller than the nr of lines in the observation\n",
    "            idx = self.window(x, window_size) #use window function to get windowed sample\n",
    "        currentObservation = x[idx] #apply idx to currentobservation\n",
    "        currentitem = currentObservation[itemIndexes[1]] #get one windowed item\n",
    "        return currentitem, y #return windowed item and its class\n",
    "\n",
    "    def batchloop(self) -> Tuple[List, List]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        for _ in range(self.batchsize): \n",
    "            x,y = self.get_windowed_item()\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    \"\"\"Iterator with additional padding of X\n",
    "\n",
    "    Args:\n",
    "        BaseDataIterator (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, window_size: int, batchsize: int) -> None:\n",
    "        super().__init__(dataset, window_size, batchsize)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index <= (len(self) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0) #if there are shorter sequences, add padding\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "dataset = BaseDataset(datapath = get_eeg())\n",
    "loader = PaddedDatagenerator(dataset = dataset, window_size=30, batchsize=32)\n",
    "\n",
    "#moeten we ervoor zorgen dat elk window max 1 keer gebruikt wordt of is het ok dat er een kleine \n",
    "# kans bestaat dat iets dubben gebruikt wordt\n",
    "\n",
    "#omgaan met train en test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000032vscode-remote?line=0'>1</a>\u001b[0m iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(loader)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000032vscode-remote?line=1'>2</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(loader)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000032vscode-remote?line=2'>3</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(loader)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000032vscode-remote?line=3'>4</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(loader)\n",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 23'\u001b[0m in \u001b[0;36mPaddedDatagenerator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=90'>91</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=91'>92</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchsize):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=92'>93</a>\u001b[0m         X, Y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatchloop()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=93'>94</a>\u001b[0m         X_ \u001b[39m=\u001b[39m pad_sequence(X, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding_value\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m#if there are shorter sequences, add padding\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=94'>95</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m X_, torch\u001b[39m.\u001b[39mtensor(Y)\n",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 23'\u001b[0m in \u001b[0;36mBaseDataIterator.batchloop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=72'>73</a>\u001b[0m Y \u001b[39m=\u001b[39m []  \u001b[39m# noqa N806\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=73'>74</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchsize): \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=74'>75</a>\u001b[0m     x,y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_windowed_item()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=75'>76</a>\u001b[0m     X\u001b[39m.\u001b[39mappend(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=76'>77</a>\u001b[0m     Y\u001b[39m.\u001b[39mappend(y)\n",
      "\u001b[1;32m/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb Cell 23'\u001b[0m in \u001b[0;36mBaseDataIterator.get_windowed_item\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=65'>66</a>\u001b[0m     idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow(x, window_size) \u001b[39m#use window function to get windowed sample\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=66'>67</a>\u001b[0m currentObservation \u001b[39m=\u001b[39m x[idx] \u001b[39m#apply idx to currentobservation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=67'>68</a>\u001b[0m currentitem \u001b[39m=\u001b[39m currentObservation[itemIndexes[\u001b[39m1\u001b[39;49m]] \u001b[39m#get one windowed item\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a224e696e6b654d4c227d/home/mladmin/code/ProjectML/projectml/notebooks/exercise/06_excercise.ipynb#ch0000019vscode-remote?line=68'>69</a>\u001b[0m \u001b[39mreturn\u001b[39;00m currentitem, y\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "iterator = iter(loader)\n",
    "batch = next(loader)\n",
    "batch = next(loader)\n",
    "batch = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 21, 14])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[4285.6401, 3993.3301, 4265.1299,  ..., 4255.3799, 4589.2300,\n",
       "           4352.3101],\n",
       "          [4292.3101, 3998.9700, 4262.5601,  ..., 4258.4600, 4597.9502,\n",
       "           4352.8198],\n",
       "          [4291.2798, 4003.0801, 4264.1001,  ..., 4265.1299, 4601.5400,\n",
       "           4347.6899],\n",
       "          ...,\n",
       "          [4314.8701, 4018.9700, 4280.5098,  ..., 4267.6899, 4594.8701,\n",
       "           4368.7202],\n",
       "          [4308.7202, 4017.9500, 4275.8999,  ..., 4265.1299, 4590.2598,\n",
       "           4368.7202],\n",
       "          [4303.5898, 4015.8999, 4272.3101,  ..., 4263.5898, 4581.0298,\n",
       "           4366.6699]],\n",
       " \n",
       "         [[4363.5898, 4046.1499, 4288.7202,  ..., 4293.8501, 4618.9702,\n",
       "           4401.0298],\n",
       "          [4351.7900, 4039.4900, 4279.4902,  ..., 4293.8501, 4612.8198,\n",
       "           4394.3599],\n",
       "          [4342.5601, 4032.8201, 4278.4600,  ..., 4289.7402, 4609.2300,\n",
       "           4392.3101],\n",
       "          ...,\n",
       "          [4298.4600, 3999.4900, 4267.6899,  ..., 4278.9702, 4595.8999,\n",
       "           4355.3799],\n",
       "          [4294.3599, 4000.5100, 4266.6699,  ..., 4271.7900, 4592.8198,\n",
       "           4341.0298],\n",
       "          [4285.1299, 3994.3601, 4258.9702,  ..., 4263.5898, 4579.4902,\n",
       "           4330.7700]],\n",
       " \n",
       "         [[4312.3101, 4012.8201, 4265.6401,  ..., 4283.5898, 4606.6699,\n",
       "           4380.5098],\n",
       "          [4314.8701, 4011.7900, 4266.1499,  ..., 4283.5898, 4606.1499,\n",
       "           4375.3799],\n",
       "          [4305.1299, 4007.1799, 4264.1001,  ..., 4283.0801, 4596.4102,\n",
       "           4367.6899],\n",
       "          ...,\n",
       "          [4301.5400, 4005.1299, 4265.6401,  ..., 4279.4902, 4601.0298,\n",
       "           4371.7900],\n",
       "          [4304.1001, 4012.3101, 4267.6899,  ..., 4285.1299, 4604.1001,\n",
       "           4374.8701],\n",
       "          [4306.1499, 4016.4099, 4266.1499,  ..., 4286.6699, 4604.6201,\n",
       "           4371.7900]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[4265.1299, 4010.7700, 4255.8999,  ..., 4274.8701, 4549.2300,\n",
       "           4307.1802],\n",
       "          [4263.0801, 4017.9500, 4258.4600,  ..., 4280.0000, 4551.7900,\n",
       "           4310.2598],\n",
       "          [4255.3799, 4016.9199, 4257.9502,  ..., 4276.4102, 4556.4102,\n",
       "           4308.2100],\n",
       "          ...,\n",
       "          [4249.2300, 4004.1001, 4245.6401,  ..., 4264.1001, 4552.8198,\n",
       "           4307.1802],\n",
       "          [4252.3101, 4003.5901, 4244.6201,  ..., 4271.7900, 4565.1299,\n",
       "           4319.4902],\n",
       "          [4257.4399, 4007.6899, 4245.1299,  ..., 4273.8501, 4566.6699,\n",
       "           4312.3101]],\n",
       " \n",
       "         [[4286.6699, 4007.1799, 4256.4102,  ..., 4278.9702, 4599.4902,\n",
       "           4334.8701],\n",
       "          [4287.1802, 4006.1499, 4263.5898,  ..., 4272.8198, 4589.7402,\n",
       "           4330.7700],\n",
       "          [4280.5098, 4004.1001, 4254.3599,  ..., 4266.6699, 4589.7402,\n",
       "           4333.3301],\n",
       "          ...,\n",
       "          [4278.9702, 4017.9500, 4248.2100,  ..., 4260.5098, 4588.7202,\n",
       "           4333.3301],\n",
       "          [4275.8999, 4022.5601, 4248.7202,  ..., 4261.5400, 4585.1299,\n",
       "           4334.8701],\n",
       "          [4282.5601, 4025.1299, 4256.4102,  ..., 4267.1802, 4587.6899,\n",
       "           4338.9702]],\n",
       " \n",
       "         [[4278.4600, 3986.6699, 4249.2300,  ..., 4278.4600, 4601.5400,\n",
       "           4348.7202],\n",
       "          [4275.3799, 3985.6399, 4246.6699,  ..., 4272.3101, 4595.3799,\n",
       "           4345.6401],\n",
       "          [4278.9702, 3991.7900, 4253.3301,  ..., 4272.8198, 4596.9199,\n",
       "           4345.1299],\n",
       "          ...,\n",
       "          [4286.6699, 3997.4399, 4261.0298,  ..., 4287.1802, 4603.5898,\n",
       "           4357.4399],\n",
       "          [4293.8501, 4002.0500, 4263.0801,  ..., 4292.3101, 4609.7402,\n",
       "           4363.5898],\n",
       "          [4285.6401, 3993.8501, 4265.6401,  ..., 4286.1499, 4605.1299,\n",
       "           4355.8999]]]),\n",
       " tensor([0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = iter(loader)\n",
    "next(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PaddedDatagenerator(BaseDataIterator):\n",
    "    \"\"\"Iterator with additional padding of X\n",
    "\n",
    "    Args:\n",
    "        BaseDataIterator (_type_): _description_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset, batchsize: int) -> None:\n",
    "        super().__init__(dataset, batchsize)\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()  # noqa N806\n",
    "            X_ = pad_sequence(X, batch_first=True, padding_value=0)  # noqa N806\n",
    "            return X_, torch.tensor(Y)\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "class BaseDatastreamer:\n",
    "    \"\"\"This datastreamer will never stop\n",
    "    The dataset should have a:\n",
    "        __len__ method\n",
    "        __getitem__ method\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: BaseDataset,\n",
    "        batchsize: int,\n",
    "        preprocessor: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "        self.preprocessor = preprocessor\n",
    "        self.size = len(self.dataset)\n",
    "        self.reset_index()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def reset_index(self) -> None:\n",
    "        self.index_list = np.random.permutation(self.size)\n",
    "        self.index = 0\n",
    "\n",
    "    def batchloop(self) -> Sequence[Tuple]:\n",
    "        batch = []\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.dataset[int(self.index_list[self.index])]\n",
    "            batch.append((x, y))\n",
    "            self.index += 1\n",
    "        return batch\n",
    "\n",
    "    def stream(self) -> Iterator:\n",
    "        while True:\n",
    "            if self.index > (self.size - self.batchsize):\n",
    "                self.reset_index()\n",
    "            batch = self.batchloop()\n",
    "            if self.preprocessor is not None:\n",
    "                X, Y = self.preprocessor(batch)  # noqa N806\n",
    "            else:\n",
    "                X, Y = zip(*batch)  # noqa N806\n",
    "            yield X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import random\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from loguru import logger\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from src.data import data_tools\n",
    "from src.data.data_tools import PaddedDatagenerator, TSDataset\n",
    "\n",
    "def window(x: Tensor, n_time: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates and index that can be used to window a timeseries.\n",
    "    E.g. the single series [0, 1, 2, 3, 4, 5] can be windowed into 4 timeseries with\n",
    "    length 3 like this:\n",
    "\n",
    "    [0, 1, 2]\n",
    "    [1, 2, 3]\n",
    "    [2, 3, 4]\n",
    "    [3, 4, 5]\n",
    "\n",
    "    We now can feed 4 different timeseries into the model, instead of 1, all\n",
    "    with the same length.\n",
    "    \"\"\"\n",
    "    n_window = len(x) - n_time + 1\n",
    "    time = torch.arange(0, n_time).reshape(1, -1)\n",
    "    window = torch.arange(0, n_window).reshape(-1, 1)\n",
    "    idx = time + window\n",
    "    return idx\n",
    "\n",
    "\n",
    "\n",
    "def get_eeg(data_dir: Path = \"../../data/raw\") -> Path:\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00264/EEG%20Eye%20State.arff\"\n",
    "    datapath = tf.keras.utils.get_file(\n",
    "        \"eeg\", origin=url, untar=False, cache_dir=data_dir\n",
    "    )\n",
    "    datapath = Path(datapath)\n",
    "    logger.info(f\"Data is downloaded to {datapath}.\")\n",
    "    return datapath\n",
    "\n",
    "class Dataloader:\n",
    "    def __init__(self, datapath: Path):\n",
    "        self.path = datapath\n",
    "        self.dataset = []\n",
    "        self.process_data()\n",
    "\n",
    "    def __get_item__():\n",
    "        pass\n",
    "\n",
    "    def __len__():\n",
    "        pass\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        file = self.path\n",
    "        x_ = np.genfromtxt(file)[:, 3:]\n",
    "        x = torch.tensor(x_).type(torch.float32)\n",
    "        y = torch.tensor(int(file.parent.name) - 1)\n",
    "        self.dataset.append((x, y))\n",
    "\n",
    "class BaseDataset:\n",
    "    def __init__(self, paths: List[Path]) -> None:\n",
    "        self.paths = paths\n",
    "        random.shuffle(self.paths)\n",
    "        self.dataset = []\n",
    "        self.process_data()\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        for file in tqdm(self.paths):\n",
    "            x_ = np.genfromtxt(file)[:, 3:]\n",
    "            x = torch.tensor(x_).type(torch.float32)\n",
    "            y = torch.tensor(int(file.parent.name) - 1)\n",
    "            self.dataset.append((x, y))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[Tensor, int]:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "class BaseDataIterator:\n",
    "    def __init__(self, dataset: BaseDataset, batchsize: int):\n",
    "        self.dataset = dataset\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # the lenght is the amount of batches\n",
    "        return int(len(self.dataset) / self.batchsize)\n",
    "\n",
    "    def __iter__(self) -> BaseDataIterator:\n",
    "        # initialize index\n",
    "        self.index = 0\n",
    "        self.index_list = torch.randperm(len(self.dataset))\n",
    "        return self\n",
    "    \n",
    "    def batchloop(self) -> Tuple[Tensor, Tensor]:\n",
    "        X = []  # noqa N806\n",
    "        Y = []  # noqa N806\n",
    "        # fill the batch\n",
    "        for _ in range(self.batchsize):\n",
    "            x, y = self.dataset[int(self.index_list[self.index])]\n",
    "            X.append(x)\n",
    "            Y.append(y)\n",
    "            self.index += 1\n",
    "        return X, Y\n",
    "\n",
    "    def __next__(self) -> Tuple[Tensor, Tensor]:\n",
    "        if self.index <= (len(self.dataset) - self.batchsize):\n",
    "            X, Y = self.batchloop()\n",
    "            return X, Y\n",
    "        else:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCELoss example\n",
    "In this example, which input would you prefer for the given target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input1 = torch.tensor([0.1, 0.1, 0.7, 0.9])\n",
    "input2 = torch.tensor([0.1, 0.3, 0.6, 0.7])\n",
    "target = torch.tensor([0., 0., 1., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which loss should you pick? CrossEntropyLoss won't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "try:\n",
    "    loss(input1, target)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need BCELoss for this.\n",
    "Binary cross entropy loss works like this:\n",
    "$$X = {x_i, \\dots, x_n}$$\n",
    "\n",
    "$$l_i =-(y_i \\cdot log(x_i) + (1-y_i) \\cdot log(1-x_i))$$\n",
    "$$BCELoss = mean(l)$$\n",
    "\n",
    "Note that the labels are assumed to be either 0 or 1 (hence, the binary part).\n",
    "If a label is 0, only the second part is relevent. If the label is 1, only the first part is relevant. the default reduction is \"mean\":\n",
    "\n",
    "$$\n",
    "BCEloss = \n",
    "\\begin{cases}\n",
    "mean(-log(1 - x_i)) & \\text{if\\,} y = 0\\\\\n",
    "mean(-log(x_i)) & \\text{if\\,} y = 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can see this works nice for a sequence of 0s and 1s.\n",
    "You can see that input1 is preferred, because it is more certain of the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1682), tensor(0.3324))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(input1, target), loss(input2, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a more generic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8594)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Sigmoid() # make sure outputs are between 0 and 1\n",
    "X = torch.randn(100) # generate 100 random inputs\n",
    "yhat = m(X) # our dummy model\n",
    "\n",
    "p = torch.ones_like(yhat) / 2\n",
    "y = torch.bernoulli(p) # we create a random label sequence of 0s and 1s\n",
    "loss(yhat, y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16b8f312320cd240106b9ea4d318428341e8727b3c7d5fc1f73cfe4a3d9868ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deep-learning-E14Cnx23-py3.9': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
